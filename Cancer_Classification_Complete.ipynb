{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Type Classification from Gene Expression Data\n",
    "\n",
    "## Project Overview\n",
    "This project builds a machine learning pipeline to classify cancer types based on RNA-Seq gene expression patterns from the TCGA PANCAN dataset.\n",
    "\n",
    "**Dataset:** TCGA PANCAN HiSeq (801 samples x 20,531 genes)\n",
    "\n",
    "**Cancer Types:**\n",
    "- BRCA: Breast Invasive Carcinoma\n",
    "- COAD: Colon Adenocarcinoma\n",
    "- KIRC: Kidney Renal Clear Cell Carcinoma\n",
    "- LUAD: Lung Adenocarcinoma\n",
    "- PRAD: Prostate Adenocarcinoma\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Imports](#1.-Setup-and-Imports)\n",
    "2. [Step 1: Load and Explore Data (EDA)](#2.-Step-1:-Load-and-Explore-Data-(EDA))\n",
    "3. [Step 2: Data Preprocessing](#3.-Step-2:-Data-Preprocessing)\n",
    "4. [Step 3: Dimensionality Reduction (PCA)](#4.-Step-3:-Dimensionality-Reduction-(PCA))\n",
    "5. [Step 4: Model Building](#5.-Step-4:-Model-Building)\n",
    "6. [Step 5: Model Evaluation](#6.-Step-5:-Model-Evaluation)\n",
    "7. [Step 6: Feature Importance Analysis](#7.-Step-6:-Feature-Importance-Analysis)\n",
    "8. [Step 7: Executive Summary](#8.-Step-7:-Executive-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages if not already installed\n# !pip install xgboost"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# IMPORT LIBRARIES\n# =============================================================================\n\n# Data manipulation and numerical operations\nimport numpy as np\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\n\n# Classification Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# Evaluation Metrics\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, roc_curve, auc,\n    confusion_matrix, classification_report,\n    precision_recall_curve, average_precision_score\n)\n\n# Suppress warnings for cleaner output\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seed for reproducibility\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# Set display options\npd.set_option('display.max_columns', 50)\npd.set_option('display.width', 200)\n\n# Set plot style - use a compatible style\ntry:\n    plt.style.use('seaborn-v0_8-whitegrid')\nexcept:\n    try:\n        plt.style.use('seaborn-whitegrid')\n    except:\n        plt.style.use('ggplot')\n\nsns.set_palette('husl')\n\n# Compatibility: define display function for non-Jupyter environments\ntry:\n    from IPython.display import display\nexcept ImportError:\n    def display(x):\n        print(x)\n\nprint(\"All libraries imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Step 1: Load and Explore Data (EDA)\n",
    "\n",
    "In this section, we load the TCGA PANCAN dataset and perform exploratory data analysis to understand the structure, distribution, and characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Define file paths\n",
    "data_path = \"TCGA-PANCAN-HiSeq-801x20531/TCGA-PANCAN-HiSeq-801x20531/data.csv\"\n",
    "labels_path = \"TCGA-PANCAN-HiSeq-801x20531/TCGA-PANCAN-HiSeq-801x20531/labels.csv\"\n",
    "\n",
    "# Load gene expression data and labels\n",
    "print(\"Loading data...\")\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "labels = pd.read_csv(labels_path, index_col=0)\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Gene Expression Data Shape: {data.shape}\")\n",
    "print(f\"Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET OVERVIEW\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nNumber of Samples: {data.shape[0]}\")\n",
    "print(f\"Number of Features (Genes): {data.shape[1]}\")\n",
    "print(f\"Number of Cancer Types: {labels['Class'].nunique()}\")\n",
    "\n",
    "print(\"\\n--- First 5 Samples ---\")\n",
    "display(data.iloc[:5, :10])  # Show first 10 genes for first 5 samples\n",
    "\n",
    "print(\"\\n--- Labels Preview ---\")\n",
    "display(labels.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLASS DISTRIBUTION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate class distribution\n",
    "class_distribution = labels['Class'].value_counts()\n",
    "class_percentages = labels['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nCancer Type Distribution:\")\n",
    "print(\"-\" * 40)\n",
    "for cancer_type in class_distribution.index:\n",
    "    count = class_distribution[cancer_type]\n",
    "    pct = class_percentages[cancer_type]\n",
    "    print(f\"{cancer_type}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "colors = sns.color_palette('husl', len(class_distribution))\n",
    "bars = axes[0].bar(class_distribution.index, class_distribution.values, color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('Cancer Type', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[0].set_title('Distribution of Cancer Types', fontsize=14, fontweight='bold')\n",
    "for bar, count in zip(bars, class_distribution.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "                 str(count), ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "wedges, texts, autotexts = axes[1].pie(class_distribution.values, labels=class_distribution.index,\n",
    "                                        autopct='%1.1f%%', colors=colors, explode=[0.02]*5,\n",
    "                                        shadow=True, startangle=90)\n",
    "axes[1].set_title('Cancer Type Proportions', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('01_class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "imbalance_ratio = class_distribution.max() / class_distribution.min()\n",
    "print(f\"\\nClass Imbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"Note: Moderate class imbalance detected. Will use stratified sampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY CHECK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum().sum()\n",
    "missing_percentage = (missing_values / data.size) * 100\n",
    "print(f\"\\nMissing Values: {missing_values} ({missing_percentage:.4f}%)\")\n",
    "\n",
    "# Check for duplicate samples\n",
    "duplicate_samples = data.duplicated().sum()\n",
    "print(f\"Duplicate Samples: {duplicate_samples}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData Types:\")\n",
    "print(data.dtypes.value_counts())\n",
    "\n",
    "# Check for constant features (zero variance)\n",
    "constant_features = (data.std() == 0).sum()\n",
    "print(f\"\\nConstant Features (zero variance): {constant_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STATISTICAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Basic statistics for gene expression values\n",
    "print(\"\\n--- Gene Expression Statistics (First 10 Genes) ---\")\n",
    "display(data.iloc[:, :10].describe())\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n--- Overall Gene Expression Distribution ---\")\n",
    "all_values = data.values.flatten()\n",
    "print(f\"Min: {all_values.min():.4f}\")\n",
    "print(f\"Max: {all_values.max():.4f}\")\n",
    "print(f\"Mean: {all_values.mean():.4f}\")\n",
    "print(f\"Median: {np.median(all_values):.4f}\")\n",
    "print(f\"Std Dev: {all_values.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENE EXPRESSION DISTRIBUTION VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution of mean expression per gene\n",
    "gene_means = data.mean(axis=0)\n",
    "axes[0, 0].hist(gene_means, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Mean Expression', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Number of Genes', fontsize=12)\n",
    "axes[0, 0].set_title('Distribution of Mean Expression Across Genes', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axvline(gene_means.mean(), color='red', linestyle='--', label=f'Mean: {gene_means.mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Distribution of variance per gene\n",
    "gene_vars = data.var(axis=0)\n",
    "axes[0, 1].hist(gene_vars[gene_vars > 0], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Variance', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Number of Genes', fontsize=12)\n",
    "axes[0, 1].set_title('Distribution of Variance Across Genes', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Box plot of expression by cancer type (sample of genes)\n",
    "# Select highly variable genes\n",
    "top_var_genes = gene_vars.nlargest(5).index.tolist()\n",
    "sample_data = data[top_var_genes].copy()\n",
    "sample_data['Cancer_Type'] = labels['Class'].values\n",
    "sample_melted = sample_data.melt(id_vars='Cancer_Type', var_name='Gene', value_name='Expression')\n",
    "\n",
    "sns.boxplot(data=sample_melted, x='Cancer_Type', y='Expression', hue='Gene', ax=axes[1, 0])\n",
    "axes[1, 0].set_xlabel('Cancer Type', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Expression Level', fontsize=12)\n",
    "axes[1, 0].set_title('Expression of Top 5 Variable Genes by Cancer Type', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(title='Gene', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Correlation heatmap of top variable genes\n",
    "top_20_genes = gene_vars.nlargest(20).index.tolist()\n",
    "corr_matrix = data[top_20_genes].corr()\n",
    "sns.heatmap(corr_matrix, cmap='RdBu_r', center=0, ax=axes[1, 1],\n",
    "            xticklabels=False, yticklabels=False, cbar_kws={'shrink': 0.8})\n",
    "axes[1, 1].set_title('Correlation Heatmap (Top 20 Variable Genes)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('02_eda_visualizations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Step 2: Data Preprocessing\n",
    "\n",
    "In this section, we prepare the data for modeling:\n",
    "- Handle missing values (if any)\n",
    "- Encode target labels\n",
    "- Normalize features using StandardScaler\n",
    "- Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HANDLE MISSING VALUES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check and handle missing values\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    print(\"\\nHandling missing values with median imputation...\")\n",
    "    data = data.fillna(data.median())\n",
    "    print(\"Missing values filled.\")\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPARE FEATURES AND TARGET\n",
    "# =============================================================================\n",
    "\n",
    "# Extract features (X) and target (y)\n",
    "X = data.values\n",
    "y = labels['Class'].values\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Store class names for later use\n",
    "class_names = label_encoder.classes_\n",
    "n_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nClass Encoding:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"  {name}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE NORMALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nNormalizing features with StandardScaler...\")\n",
    "\n",
    "# Apply StandardScaler to normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\nBefore Scaling:\")\n",
    "print(f\"  Mean: {X.mean():.4f}\")\n",
    "print(f\"  Std:  {X.std():.4f}\")\n",
    "\n",
    "print(f\"\\nAfter Scaling:\")\n",
    "print(f\"  Mean: {X_scaled.mean():.6f}\")\n",
    "print(f\"  Std:  {X_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Step 3: Dimensionality Reduction (PCA)\n",
    "\n",
    "With 20,531 features, dimensionality reduction is essential to:\n",
    "- Reduce computational complexity\n",
    "- Mitigate the curse of dimensionality\n",
    "- Remove noise and redundant features\n",
    "- Improve model generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PCA ANALYSIS - VARIANCE EXPLAINED\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DIMENSIONALITY REDUCTION (PCA)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Fit PCA to understand variance distribution\n",
    "pca_full = PCA(random_state=RANDOM_STATE)\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Find optimal number of components for different thresholds\n",
    "print(\"\\nComponents needed for variance retention:\")\n",
    "print(\"-\" * 40)\n",
    "thresholds = [0.80, 0.85, 0.90, 0.95, 0.99]\n",
    "for threshold in thresholds:\n",
    "    n_comp = np.argmax(cumulative_variance >= threshold) + 1\n",
    "    print(f\"  {threshold*100:.0f}% variance: {n_comp} components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE PCA VARIANCE\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual variance explained\n",
    "n_show = 50\n",
    "axes[0].bar(range(1, n_show + 1), pca_full.explained_variance_ratio_[:n_show] * 100,\n",
    "            color='steelblue', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('Principal Component', fontsize=12)\n",
    "axes[0].set_ylabel('Explained Variance (%)', fontsize=12)\n",
    "axes[0].set_title('Variance Explained by Each PC (First 50)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Cumulative variance explained\n",
    "n_cumulative = 300\n",
    "axes[1].plot(range(1, n_cumulative + 1), cumulative_variance[:n_cumulative] * 100,\n",
    "             'b-', linewidth=2, label='Cumulative Variance')\n",
    "axes[1].axhline(y=95, color='red', linestyle='--', linewidth=1.5, label='95% Threshold')\n",
    "axes[1].axhline(y=90, color='orange', linestyle='--', linewidth=1.5, label='90% Threshold')\n",
    "axes[1].set_xlabel('Number of Components', fontsize=12)\n",
    "axes[1].set_ylabel('Cumulative Explained Variance (%)', fontsize=12)\n",
    "axes[1].set_title('Cumulative Explained Variance', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].set_ylim(0, 105)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_pca_variance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLY PCA TRANSFORMATION\n",
    "# =============================================================================\n",
    "\n",
    "# Choose number of components (95% variance retained)\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"\\nApplying PCA with {n_components} components (95% variance retained)\")\n",
    "\n",
    "# Fit and transform\n",
    "pca = PCA(n_components=n_components, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"\\nOriginal shape: {X_scaled.shape}\")\n",
    "print(f\"Reduced shape:  {X_pca.shape}\")\n",
    "print(f\"Dimensionality reduction: {X_scaled.shape[1]} -> {X_pca.shape[1]} ({(1 - X_pca.shape[1]/X_scaled.shape[1])*100:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE PCA - 2D AND 3D PROJECTIONS\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 2D PCA Plot\n",
    "colors = sns.color_palette('husl', n_classes)\n",
    "for i, (cancer_type, color) in enumerate(zip(class_names, colors)):\n",
    "    mask = y_encoded == i\n",
    "    axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1], c=[color], label=cancer_type,\n",
    "                    alpha=0.7, s=50, edgecolors='white', linewidths=0.5)\n",
    "\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=12)\n",
    "axes[0].set_title('Cancer Samples in 2D PCA Space', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(title='Cancer Type', loc='best')\n",
    "\n",
    "# PC1 vs PC3\n",
    "for i, (cancer_type, color) in enumerate(zip(class_names, colors)):\n",
    "    mask = y_encoded == i\n",
    "    axes[1].scatter(X_pca[mask, 0], X_pca[mask, 2], c=[color], label=cancer_type,\n",
    "                    alpha=0.7, s=50, edgecolors='white', linewidths=0.5)\n",
    "\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=12)\n",
    "axes[1].set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.1f}% variance)', fontsize=12)\n",
    "axes[1].set_title('Cancer Samples: PC1 vs PC3', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(title='Cancer Type', loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_pca_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3D PCA VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i, (cancer_type, color) in enumerate(zip(class_names, colors)):\n",
    "    mask = y_encoded == i\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n",
    "               c=[color], label=cancer_type, alpha=0.7, s=50)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]*100:.1f}%)')\n",
    "ax.set_title('Cancer Samples in 3D PCA Space', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Cancer Type', loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('05_pca_3d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Split data with stratification to maintain class proportions\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Set: {X_train.shape[0]} samples ({X_train.shape[0]/len(y_encoded)*100:.0f}%)\")\n",
    "print(f\"Test Set: {X_test.shape[0]} samples ({X_test.shape[0]/len(y_encoded)*100:.0f}%)\")\n",
    "\n",
    "# Verify stratification\n",
    "print(\"\\nClass distribution in splits:\")\n",
    "print(\"-\" * 50)\n",
    "for i, name in enumerate(class_names):\n",
    "    train_count = (y_train == i).sum()\n",
    "    test_count = (y_test == i).sum()\n",
    "    print(f\"{name}: Train={train_count}, Test={test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. Step 4: Model Building\n\nWe will train and compare multiple classification models:\n1. **Logistic Regression** (Baseline)\n2. **Decision Tree Classifier**\n3. **Random Forest Classifier**\n4. **XGBoost Classifier**\n5. **Gradient Boosting Classifier**\n\nWe will also perform hyperparameter tuning using GridSearchCV."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEFINE MODELS\n# =============================================================================\n\nprint(\"=\" * 70)\nprint(\"MODEL BUILDING\")\nprint(\"=\" * 70)\n\n# Define all models with their configurations\nmodels = {\n    'Logistic Regression': LogisticRegression(\n        max_iter=1000,\n        random_state=RANDOM_STATE,\n        multi_class='multinomial',\n        solver='lbfgs'\n    ),\n    'Decision Tree': DecisionTreeClassifier(\n        max_depth=15,\n        min_samples_split=5,\n        random_state=RANDOM_STATE\n    ),\n    'Random Forest': RandomForestClassifier(\n        n_estimators=200,\n        max_depth=20,\n        min_samples_split=5,\n        random_state=RANDOM_STATE,\n        n_jobs=1\n    ),\n    'XGBoost': XGBClassifier(\n        n_estimators=200,\n        max_depth=6,\n        learning_rate=0.1,\n        random_state=RANDOM_STATE,\n        use_label_encoder=False,\n        eval_metric='mlogloss',\n        n_jobs=1\n    ),\n    'Gradient Boosting': GradientBoostingClassifier(\n        n_estimators=200,\n        max_depth=6,\n        learning_rate=0.1,\n        random_state=RANDOM_STATE\n    )\n}\n\nprint(f\"\\nModels to train: {len(models)}\")\nfor name in models:\n    print(f\"  - {name}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN ALL MODELS\n",
    "# =============================================================================\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"\\nTraining models...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=1)\n",
    "    print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    # Train on full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Probability predictions (for AUC-ROC)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_test_proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_test_proba = None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'cv_scores': cv_scores,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'y_test_proba': y_test_proba\n",
    "    }\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfit_gap = train_accuracy - test_accuracy\n",
    "    if overfit_gap > 0.1:\n",
    "        print(f\"  WARNING: Possible overfitting (gap: {overfit_gap:.4f})\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING WITH GRIDSEARCHCV\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HYPERPARAMETER TUNING (GridSearchCV)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Tune XGBoost using GridSearchCV\n",
    "print(\"\\nTuning XGBoost hyperparameters...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=RANDOM_STATE,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Update XGBoost with best parameters\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_test_pred_tuned = best_xgb.predict(X_test)\n",
    "tuned_accuracy = accuracy_score(y_test, y_test_pred_tuned)\n",
    "\n",
    "print(f\"\\nTuned XGBoost Test Accuracy: {tuned_accuracy:.4f}\")\n",
    "print(f\"Original XGBoost Test Accuracy: {results['XGBoost']['test_accuracy']:.4f}\")\n",
    "print(f\"Improvement: {(tuned_accuracy - results['XGBoost']['test_accuracy'])*100:.2f}%\")\n",
    "\n",
    "# Update results with tuned model\n",
    "results['XGBoost (Tuned)'] = {\n",
    "    'model': best_xgb,\n",
    "    'cv_scores': np.array([grid_search.best_score_] * 5),\n",
    "    'train_accuracy': accuracy_score(y_train, best_xgb.predict(X_train)),\n",
    "    'test_accuracy': tuned_accuracy,\n",
    "    'y_train_pred': best_xgb.predict(X_train),\n",
    "    'y_test_pred': y_test_pred_tuned,\n",
    "    'y_test_proba': best_xgb.predict_proba(X_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DUMMY SAMPLE PREDICTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DUMMY SAMPLE PREDICTION EXAMPLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a dummy sample by taking the mean of each cancer type\n",
    "print(\"\\nCreating dummy sample from class centroids...\\n\")\n",
    "\n",
    "# Get the best model (Logistic Regression performed best)\n",
    "best_model_name = max(results, key=lambda x: results[x]['test_accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "# Create dummy samples (one per class centroid)\n",
    "for i, cancer_type in enumerate(class_names):\n",
    "    # Get class centroid in PCA space\n",
    "    class_mask = y_encoded == i\n",
    "    centroid = X_pca[class_mask].mean(axis=0).reshape(1, -1)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = best_model.predict(centroid)\n",
    "    predicted_class = class_names[prediction[0]]\n",
    "    \n",
    "    # Get probability\n",
    "    if hasattr(best_model, 'predict_proba'):\n",
    "        proba = best_model.predict_proba(centroid)[0]\n",
    "        confidence = proba[prediction[0]] * 100\n",
    "    else:\n",
    "        confidence = 'N/A'\n",
    "    \n",
    "    print(f\"Dummy sample (centroid of {cancer_type}):\")\n",
    "    print(f\"  -> Predicted: {predicted_class}\")\n",
    "    print(f\"  -> Confidence: {confidence:.1f}%\")\n",
    "    print(f\"  -> Correct: {'Yes' if predicted_class == cancer_type else 'No'}\")\n",
    "    print()\n",
    "\n",
    "# Also predict on a random test sample\n",
    "print(\"\\n--- Random Test Sample Prediction ---\")\n",
    "random_idx = np.random.randint(0, len(X_test))\n",
    "sample = X_test[random_idx].reshape(1, -1)\n",
    "true_label = class_names[y_test[random_idx]]\n",
    "pred_label = class_names[best_model.predict(sample)[0]]\n",
    "\n",
    "print(f\"Sample Index: {random_idx}\")\n",
    "print(f\"True Label: {true_label}\")\n",
    "print(f\"Predicted Label: {pred_label}\")\n",
    "\n",
    "if hasattr(best_model, 'predict_proba'):\n",
    "    proba = best_model.predict_proba(sample)[0]\n",
    "    print(f\"\\nPrediction Probabilities:\")\n",
    "    for name, prob in zip(class_names, proba):\n",
    "        print(f\"  {name}: {prob*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Step 5: Model Evaluation\n",
    "\n",
    "Comprehensive evaluation using multiple metrics:\n",
    "- Accuracy\n",
    "- Precision, Recall, F1-Score\n",
    "- AUC-ROC\n",
    "- TPR (True Positive Rate) / TNR (True Negative Rate)\n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE MODEL EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred, y_proba=None, class_names=None):\n",
    "    \"\"\"Calculate comprehensive classification metrics.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['Precision (Weighted)'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['Recall (Weighted)'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['F1 (Weighted)'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    metrics['Precision (Macro)'] = precision_score(y_true, y_pred, average='macro')\n",
    "    metrics['Recall (Macro)'] = recall_score(y_true, y_pred, average='macro')\n",
    "    metrics['F1 (Macro)'] = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # AUC-ROC (One-vs-Rest)\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            metrics['AUC-ROC (OvR)'] = roc_auc_score(y_true, y_proba, multi_class='ovr')\n",
    "        except:\n",
    "            metrics['AUC-ROC (OvR)'] = np.nan\n",
    "    else:\n",
    "        metrics['AUC-ROC (OvR)'] = np.nan\n",
    "    \n",
    "    # Calculate TPR and TNR for each class\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    n_classes = len(cm)\n",
    "    \n",
    "    tpr_list = []  # Sensitivity / Recall\n",
    "    tnr_list = []  # Specificity\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        tp = cm[i, i]\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - tp - fn - fp\n",
    "        \n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        tnr_list.append(tnr)\n",
    "    \n",
    "    metrics['TPR (Avg)'] = np.mean(tpr_list)\n",
    "    metrics['TNR (Avg)'] = np.mean(tnr_list)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for all models\n",
    "evaluation_results = []\n",
    "\n",
    "for name, result in results.items():\n",
    "    metrics = calculate_metrics(\n",
    "        y_test, \n",
    "        result['y_test_pred'], \n",
    "        result['y_test_proba'],\n",
    "        class_names\n",
    "    )\n",
    "    metrics['Model'] = name\n",
    "    evaluation_results.append(metrics)\n",
    "\n",
    "# Create DataFrame\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "eval_df = eval_df.set_index('Model')\n",
    "\n",
    "# Display results\n",
    "print(\"\\n--- Comprehensive Model Comparison ---\\n\")\n",
    "display(eval_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE MODEL COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "# Select key metrics for visualization\n",
    "key_metrics = ['Accuracy', 'F1 (Weighted)', 'AUC-ROC (OvR)', 'TPR (Avg)', 'TNR (Avg)']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "model_names = eval_df.index.tolist()\n",
    "x = np.arange(len(model_names))\n",
    "colors = sns.color_palette('husl', len(model_names))\n",
    "\n",
    "for idx, metric in enumerate(key_metrics):\n",
    "    values = eval_df[metric].values\n",
    "    bars = axes[idx].bar(x, values, color=colors, edgecolor='black')\n",
    "    axes[idx].set_xlabel('Model', fontsize=11)\n",
    "    axes[idx].set_ylabel(metric, fontsize=11)\n",
    "    axes[idx].set_title(f'{metric} by Model', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xticks(x)\n",
    "    axes[idx].set_xticklabels(model_names, rotation=45, ha='right', fontsize=9)\n",
    "    axes[idx].set_ylim(0, 1.05)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        if not np.isnan(val):\n",
    "            axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                          f'{val:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Summary comparison in last subplot\n",
    "axes[5].axis('off')\n",
    "best_model_idx = eval_df['F1 (Weighted)'].idxmax()\n",
    "summary_text = f\"\"\"BEST MODEL: {best_model_idx}\n",
    "\n",
    "Key Metrics:\n",
    "- Accuracy: {eval_df.loc[best_model_idx, 'Accuracy']:.4f}\n",
    "- F1 Score: {eval_df.loc[best_model_idx, 'F1 (Weighted)']:.4f}\n",
    "- AUC-ROC: {eval_df.loc[best_model_idx, 'AUC-ROC (OvR)']:.4f}\n",
    "- TPR: {eval_df.loc[best_model_idx, 'TPR (Avg)']:.4f}\n",
    "- TNR: {eval_df.loc[best_model_idx, 'TNR (Avg)']:.4f}\n",
    "\"\"\"\n",
    "axes[5].text(0.1, 0.5, summary_text, transform=axes[5].transAxes,\n",
    "             fontsize=12, verticalalignment='center',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('06_model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFUSION MATRICES\n# =============================================================================\n\n# Plot confusion matrices for top 4 models\ntop_models = ['Logistic Regression', 'Random Forest', 'XGBoost', 'Gradient Boosting']\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\naxes = axes.flatten()\n\nfor idx, model_name in enumerate(top_models):\n    y_pred = results[model_name]['y_test_pred']\n    cm = confusion_matrix(y_test, y_pred)\n    \n    # Calculate percentages\n    cm_pct = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    \n    # Create annotations with both count and percentage\n    annotations = np.empty_like(cm, dtype=object)\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            annotations[i, j] = f'{cm[i, j]}\\n({cm_pct[i, j]:.1f}%)'\n    \n    sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues', ax=axes[idx],\n                xticklabels=class_names, yticklabels=class_names,\n                cbar_kws={'shrink': 0.8})\n    axes[idx].set_xlabel('Predicted', fontsize=11)\n    axes[idx].set_ylabel('Actual', fontsize=11)\n    acc = results[model_name]['test_accuracy']\n    axes[idx].set_title(f'{model_name}\\nAccuracy: {acc:.4f}', fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('07_confusion_matrices.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# ROC CURVES (One-vs-Rest)\n# =============================================================================\n\nfrom sklearn.preprocessing import label_binarize\n\n# Binarize the output for ROC curve\ny_test_bin = label_binarize(y_test, classes=range(n_classes))\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\naxes = axes.flatten()\n\nfor idx, model_name in enumerate(top_models):\n    y_proba = results[model_name]['y_test_proba']\n    \n    if y_proba is not None:\n        # Plot ROC curve for each class\n        for i, (class_name, color) in enumerate(zip(class_names, colors)):\n            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n            roc_auc = auc(fpr, tpr)\n            axes[idx].plot(fpr, tpr, color=color, lw=2,\n                          label=f'{class_name} (AUC = {roc_auc:.3f})')\n        \n        # Plot diagonal\n        axes[idx].plot([0, 1], [0, 1], 'k--', lw=1.5, label='Random')\n        axes[idx].set_xlim([0.0, 1.0])\n        axes[idx].set_ylim([0.0, 1.05])\n        axes[idx].set_xlabel('False Positive Rate', fontsize=11)\n        axes[idx].set_ylabel('True Positive Rate', fontsize=11)\n        axes[idx].set_title(f'ROC Curves - {model_name}', fontsize=12, fontweight='bold')\n        axes[idx].legend(loc='lower right', fontsize=9)\n\nplt.tight_layout()\nplt.savefig('08_roc_curves.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DETAILED CLASSIFICATION REPORT FOR BEST MODEL\n",
    "# =============================================================================\n",
    "\n",
    "best_model_name = eval_df['F1 (Weighted)'].idxmax()\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"DETAILED CLASSIFICATION REPORT - {best_model_name}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(classification_report(y_test, results[best_model_name]['y_test_pred'], \n",
    "                           target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OVERFITTING/UNDERFITTING ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OVERFITTING/UNDERFITTING ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n{:<25} {:>15} {:>15} {:>15} {:>15}\".format(\n",
    "    'Model', 'Train Acc', 'Test Acc', 'Gap', 'Status'))\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for name, result in results.items():\n",
    "    train_acc = result['train_accuracy']\n",
    "    test_acc = result['test_accuracy']\n",
    "    gap = train_acc - test_acc\n",
    "    \n",
    "    if gap > 0.15:\n",
    "        status = 'OVERFITTING'\n",
    "    elif test_acc < 0.85:\n",
    "        status = 'UNDERFITTING'\n",
    "    else:\n",
    "        status = 'Good Fit'\n",
    "    \n",
    "    print(\"{:<25} {:>15.4f} {:>15.4f} {:>15.4f} {:>15}\".format(\n",
    "        name, train_acc, test_acc, gap, status))\n",
    "\n",
    "# Visualize train vs test accuracy\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "model_names = list(results.keys())\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "train_accs = [results[m]['train_accuracy'] for m in model_names]\n",
    "test_accs = [results[m]['test_accuracy'] for m in model_names]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, train_accs, width, label='Train Accuracy', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, test_accs, width, label='Test Accuracy', color='coral')\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Train vs Test Accuracy (Overfitting Analysis)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0.7, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('09_overfitting_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Step 6: Feature Importance Analysis\n",
    "\n",
    "Analyze which features (genes/PCA components) are most influential in the classification:\n",
    "- Logistic Regression: Model coefficients\n",
    "- Tree-based models: Feature importance scores\n",
    "- Map back to original genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOGISTIC REGRESSION COEFFICIENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n--- Logistic Regression Coefficients ---\\n\")\n",
    "\n",
    "lr_model = results['Logistic Regression']['model']\n",
    "coefficients = lr_model.coef_\n",
    "\n",
    "print(f\"Coefficient matrix shape: {coefficients.shape}\")\n",
    "print(f\"(Classes x PCA Components)\")\n",
    "\n",
    "# Calculate average absolute coefficient per component\n",
    "avg_coef = np.mean(np.abs(coefficients), axis=0)\n",
    "\n",
    "# Get top 20 most important PCA components\n",
    "top_20_idx = np.argsort(avg_coef)[-20:][::-1]\n",
    "\n",
    "print(\"\\nTop 20 Most Important PCA Components (Logistic Regression):\")\n",
    "print(\"-\" * 50)\n",
    "for i, idx in enumerate(top_20_idx[:10], 1):\n",
    "    print(f\"  {i:2d}. PC{idx+1}: {avg_coef[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TREE-BASED FEATURE IMPORTANCE\n# =============================================================================\n\nprint(\"\\n--- Tree-Based Models Feature Importance ---\\n\")\n\n# Get feature importance from different models\ntree_models = ['Decision Tree', 'Random Forest', 'XGBoost', 'Gradient Boosting']\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\naxes = axes.flatten()\n\nfor idx, model_name in enumerate(tree_models):\n    model = results[model_name]['model']\n    \n    # Get feature importance\n    if hasattr(model, 'feature_importances_'):\n        importance = model.feature_importances_\n    else:\n        continue\n    \n    # Get top 20\n    top_idx = np.argsort(importance)[-20:][::-1]\n    top_importance = importance[top_idx]\n    \n    # Plot\n    y_pos = np.arange(20)\n    axes[idx].barh(y_pos, top_importance[::-1], color='steelblue', edgecolor='black')\n    axes[idx].set_yticks(y_pos)\n    axes[idx].set_yticklabels([f'PC{i+1}' for i in top_idx[::-1]])\n    axes[idx].set_xlabel('Importance', fontsize=11)\n    axes[idx].set_title(f'{model_name} - Top 20 Important Components', fontsize=12, fontweight='bold')\n    axes[idx].invert_yaxis()\n\nplt.tight_layout()\nplt.savefig('10_pca_feature_importance.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAP BACK TO ORIGINAL GENES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Mapping Feature Importance to Original Genes ---\\n\")\n",
    "\n",
    "# Use Random Forest importance for mapping\n",
    "rf_importance = results['Random Forest']['model'].feature_importances_\n",
    "\n",
    "# Calculate gene importance by weighting PCA loadings\n",
    "gene_importance = np.zeros(data.shape[1])\n",
    "\n",
    "for i in range(min(n_components, len(rf_importance))):\n",
    "    gene_importance += rf_importance[i] * np.abs(pca.components_[i])\n",
    "\n",
    "# Get top 30 genes\n",
    "top_30_gene_idx = np.argsort(gene_importance)[-30:][::-1]\n",
    "top_30_gene_names = data.columns[top_30_gene_idx]\n",
    "top_30_gene_importance = gene_importance[top_30_gene_idx]\n",
    "\n",
    "print(\"Top 30 Most Important Genes for Cancer Classification:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (gene, imp) in enumerate(zip(top_30_gene_names, top_30_gene_importance), 1):\n",
    "    print(f\"  {i:2d}. {gene}: {imp:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE TOP GENES\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Bar chart of top 20 genes\n",
    "top_20_genes = top_30_gene_names[:20]\n",
    "top_20_importance = top_30_gene_importance[:20]\n",
    "\n",
    "y_pos = np.arange(20)\n",
    "axes[0].barh(y_pos, top_20_importance[::-1], color='darkgreen', edgecolor='black')\n",
    "axes[0].set_yticks(y_pos)\n",
    "axes[0].set_yticklabels(top_20_genes[::-1])\n",
    "axes[0].set_xlabel('Importance Score', fontsize=12)\n",
    "axes[0].set_title('Top 20 Most Important Genes', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Heatmap of top 10 genes across cancer types\n",
    "top_10_genes = top_30_gene_names[:10]\n",
    "mean_expression = pd.DataFrame(index=top_10_genes)\n",
    "\n",
    "for cancer in class_names:\n",
    "    mask = labels['Class'] == cancer\n",
    "    mean_expression[cancer] = data.loc[mask, top_10_genes].mean()\n",
    "\n",
    "# Z-score normalization\n",
    "mean_expression_norm = (mean_expression.T - mean_expression.T.mean()) / mean_expression.T.std()\n",
    "\n",
    "sns.heatmap(mean_expression_norm.T, cmap='RdBu_r', center=0, annot=True, fmt='.2f',\n",
    "            ax=axes[1], cbar_kws={'label': 'Z-Score'})\n",
    "axes[1].set_title('Top 10 Genes Expression Across Cancer Types', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Cancer Type', fontsize=12)\n",
    "axes[1].set_ylabel('Gene', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('11_gene_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOGISTIC REGRESSION COEFFICIENTS PER CLASS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Logistic Regression: Class-Specific Important Features ---\\n\")\n",
    "\n",
    "# Get top genes for each cancer type\n",
    "for i, cancer_type in enumerate(class_names):\n",
    "    class_coef = coefficients[i]\n",
    "    \n",
    "    # Map to genes\n",
    "    gene_coef = np.zeros(data.shape[1])\n",
    "    for j in range(len(class_coef)):\n",
    "        gene_coef += class_coef[j] * pca.components_[j]\n",
    "    \n",
    "    # Get top positive and negative genes\n",
    "    top_positive_idx = np.argsort(gene_coef)[-5:][::-1]\n",
    "    top_negative_idx = np.argsort(gene_coef)[:5]\n",
    "    \n",
    "    print(f\"\\n{cancer_type}:\")\n",
    "    print(f\"  Positive indicators (higher expression -> more likely {cancer_type}):\")\n",
    "    for idx in top_positive_idx:\n",
    "        print(f\"    - {data.columns[idx]}: {gene_coef[idx]:.4f}\")\n",
    "    print(f\"  Negative indicators (lower expression -> more likely {cancer_type}):\")\n",
    "    for idx in top_negative_idx:\n",
    "        print(f\"    - {data.columns[idx]}: {gene_coef[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Step 7: Executive Summary\n",
    "\n",
    "### Project Goal\n",
    "Develop a machine learning model to classify cancer types based on RNA-Seq gene expression patterns from the TCGA PANCAN dataset.\n",
    "\n",
    "### Dataset Overview\n",
    "- **Source:** The Cancer Genome Atlas (TCGA) PANCAN HiSeq dataset\n",
    "- **Samples:** 801 patient samples\n",
    "- **Features:** 20,531 genes (RNA-Seq expression values)\n",
    "- **Classes:** 5 cancer types (BRCA, COAD, KIRC, LUAD, PRAD)\n",
    "- **Class Distribution:** Imbalanced (BRCA: 300, COAD: 78)\n",
    "\n",
    "### Preprocessing\n",
    "1. No missing values detected\n",
    "2. StandardScaler normalization applied\n",
    "3. PCA dimensionality reduction: 20,531  530 features (95% variance retained)\n",
    "4. Stratified train-test split (80-20)\n",
    "\n",
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# EXECUTIVE SUMMARY\n# =============================================================================\n\nprint(\"=\" * 70)\nprint(\"EXECUTIVE SUMMARY\")\nprint(\"=\" * 70)\n\nprint(\"\"\"\nPROJECT: Cancer Type Classification from Gene Expression Data\n======================================================================\n\n1. OBJECTIVE\n   Develop a machine learning pipeline to accurately classify cancer\n   types based on RNA-Seq gene expression patterns.\n\n2. DATASET\n   - Source: TCGA PANCAN HiSeq dataset\n   - Samples: 801 patients\n   - Features: 20,531 genes\n   - Classes: 5 cancer types (BRCA, COAD, KIRC, LUAD, PRAD)\n\"\"\")\n\n# Best model summary\nbest_model_name = eval_df['F1 (Weighted)'].idxmax()\nbest_metrics = eval_df.loc[best_model_name]\n\nprint(f\"\"\"3. BEST PERFORMING MODEL: {best_model_name}\n   \n   Key Metrics:\n   - Accuracy:         {best_metrics['Accuracy']:.4f} ({best_metrics['Accuracy']*100:.2f}%)\n   - Precision:        {best_metrics['Precision (Weighted)']:.4f}\n   - Recall:           {best_metrics['Recall (Weighted)']:.4f}\n   - F1-Score:         {best_metrics['F1 (Weighted)']:.4f}\n   - AUC-ROC:          {best_metrics['AUC-ROC (OvR)']:.4f}\n   - True Positive Rate: {best_metrics['TPR (Avg)']:.4f}\n   - True Negative Rate: {best_metrics['TNR (Avg)']:.4f}\n\"\"\")\n\nprint(\"\"\"4. KEY FINDINGS\n   \n   a) Model Comparison:\n      - Logistic Regression achieved highest accuracy\n      - Decision Tree showed signs of overfitting\n      - Ensemble methods (Random Forest, XGBoost, Gradient Boosting) performed well\n   \n   b) Important Genes:\"\"\")\n\nprint(f\"      Top 5 genes: {', '.join(top_30_gene_names[:5])}\")\n\nprint(\"\"\"\n   c) Cancer Type Separability:\n      - KIRC (Kidney) and BRCA (Breast) show distinct expression patterns\n      - LUAD (Lung) and COAD (Colon) show some overlap\n      - PCA visualization shows good class separation\n\n5. LIMITATIONS\n   \n   - Class imbalance (BRCA: 300 vs COAD: 78 samples)\n   - Gene names are anonymized (gene_0, gene_1, etc.)\n   - Limited to 5 cancer types\n   - No external validation dataset\n\n6. RECOMMENDATIONS\n   \n   - Use Logistic Regression for production deployment (best accuracy)\n   - Consider ensemble methods for improved robustness\n   - Validate on independent datasets before clinical use\n   - Investigate identified genes for biological significance\n   - Address class imbalance with SMOTE or class weighting\n\n======================================================================\n\"\"\")\n\n# Final model comparison table\nprint(\"\\nMODEL COMPARISON TABLE:\")\nprint(\"=\" * 70)\nsummary_cols = ['Accuracy', 'Precision (Weighted)', 'Recall (Weighted)', 'F1 (Weighted)', 'AUC-ROC (OvR)']\ndisplay(eval_df[summary_cols].sort_values('F1 (Weighted)', ascending=False).round(4))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE FINAL SUMMARY VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Create grid\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Class distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "colors = sns.color_palette('husl', len(class_distribution))\n",
    "ax1.bar(class_distribution.index, class_distribution.values, color=colors)\n",
    "ax1.set_title('Cancer Type Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Cancer Type')\n",
    "ax1.set_ylabel('Count')\n",
    "\n",
    "# 2. PCA 2D\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "for i, (cancer_type, color) in enumerate(zip(class_names, colors)):\n",
    "    mask = y_encoded == i\n",
    "    ax2.scatter(X_pca[mask, 0], X_pca[mask, 1], c=[color], label=cancer_type, alpha=0.6, s=20)\n",
    "ax2.set_title('PCA Visualization', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC2')\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "# 3. Model accuracy comparison\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "model_accs = eval_df['Accuracy'].sort_values(ascending=True)\n",
    "ax3.barh(range(len(model_accs)), model_accs.values, color='steelblue')\n",
    "ax3.set_yticks(range(len(model_accs)))\n",
    "ax3.set_yticklabels(model_accs.index, fontsize=8)\n",
    "ax3.set_title('Model Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Accuracy')\n",
    "ax3.set_xlim(0.8, 1.0)\n",
    "\n",
    "# 4. Confusion matrix (best model)\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "cm = confusion_matrix(y_test, results[best_model_name]['y_test_pred'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax4.set_title(f'Confusion Matrix ({best_model_name})', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Predicted')\n",
    "ax4.set_ylabel('Actual')\n",
    "\n",
    "# 5. Top 10 important genes\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ax5.barh(range(10), top_30_gene_importance[:10][::-1], color='darkgreen')\n",
    "ax5.set_yticks(range(10))\n",
    "ax5.set_yticklabels(top_30_gene_names[:10][::-1], fontsize=8)\n",
    "ax5.set_title('Top 10 Important Genes', fontsize=12, fontweight='bold')\n",
    "ax5.set_xlabel('Importance')\n",
    "\n",
    "# 6. ROC curve for best model\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "y_proba = results[best_model_name]['y_test_proba']\n",
    "if y_proba is not None:\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax6.plot(fpr, tpr, color=color, lw=1.5, label=f'{class_name} ({roc_auc:.2f})')\n",
    "    ax6.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    ax6.set_title(f'ROC Curves ({best_model_name})', fontsize=12, fontweight='bold')\n",
    "    ax6.set_xlabel('FPR')\n",
    "    ax6.set_ylabel('TPR')\n",
    "    ax6.legend(fontsize=7, loc='lower right')\n",
    "\n",
    "# 7. Summary text\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "ax7.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "EXECUTIVE SUMMARY\n",
    "{'='*80}\n",
    "Dataset: TCGA PANCAN RNA-Seq (801 samples, 20,531 genes, 5 cancer types)\n",
    "Best Model: {best_model_name}\n",
    "Test Accuracy: {best_metrics['Accuracy']*100:.2f}%  |  F1-Score: {best_metrics['F1 (Weighted)']:.4f}  |  AUC-ROC: {best_metrics['AUC-ROC (OvR)']:.4f}\n",
    "Top Genes: {', '.join(top_30_gene_names[:5])}\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "ax7.text(0.5, 0.5, summary_text, transform=ax7.transAxes, fontsize=11,\n",
    "         verticalalignment='center', horizontalalignment='center',\n",
    "         family='monospace', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Cancer Type Classification - Summary Dashboard', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.savefig('12_executive_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All visualizations saved successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIST ALL GENERATED FILES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGenerated Visualization Files:\")\n",
    "print(\"=\" * 40)\n",
    "files = [\n",
    "    '01_class_distribution.png',\n",
    "    '02_eda_visualizations.png',\n",
    "    '03_pca_variance.png',\n",
    "    '04_pca_visualization.png',\n",
    "    '05_pca_3d.png',\n",
    "    '06_model_comparison.png',\n",
    "    '07_confusion_matrices.png',\n",
    "    '08_roc_curves.png',\n",
    "    '09_overfitting_analysis.png',\n",
    "    '10_pca_feature_importance.png',\n",
    "    '11_gene_importance.png',\n",
    "    '12_executive_summary.png'\n",
    "]\n",
    "for f in files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CANCER TYPE CLASSIFICATION PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}